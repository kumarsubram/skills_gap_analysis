"""
Smart Processing Summary and Reporting Functions for GitHub Medallion Pipeline

ğŸ§  FIXED: Table naming consistency - uses same Gold table name as all other files
No manual configuration needed - truly idempotent behavior.

Place at: include/utils/github_processing_summary.py
"""

from datetime import datetime, timezone
from typing import Dict
from deltalake import DeltaTable

from include.utils.delta_table_utils import (
    get_enterprise_table_path,
    get_minio_storage_options
)
from include.utils.github_medallion_processing import assess_processing_status
from include.utils.github_date_processing import get_processing_dates
from include.utils.github_table_initialization import ensure_github_silver_gold_tables_exist

# FIXED: Use SAME table name as all other files
GOLD_TABLE_NAME = "technology_daily_activity"


def ensure_tables_ready(**context) -> Dict:
    """Ensure Silver and Gold tables exist with proper schemas"""
    print("ğŸ—ï¸ ENSURING MEDALLION TABLES READY")
    print("=" * 40)
    print("âœ… Using corrected schemas with business domain focus")
    print("âœ… Gold layer: Business classifications (not statistics)")
    
    try:
        result = ensure_github_silver_gold_tables_exist()
        
        if result['success']:
            print("âœ… All medallion tables ready with corrected schemas")
            print("ğŸ¯ Ready for Bronze â†’ Silver â†’ Gold processing")
            return {
                'status': 'success',
                'tables_ready': True,
                'message': 'Medallion architecture tables ready'
            }
        else:
            print("âŒ Table initialization failed")
            print("ğŸ’¡ Check MinIO connection and table creation permissions")
            return {
                'status': 'failed',
                'tables_ready': False,
                'message': 'Could not initialize medallion tables'
            }
            
    except Exception as e:
        print(f"âŒ Table readiness check failed: {e}")
        return {
            'status': 'failed',
            'tables_ready': False,
            'error': str(e),
            'message': f'Table check error: {str(e)}'
        }


def generate_business_intelligence_insights(gold_df, date_str: str) -> None:
    """Generate detailed business intelligence insights from Gold data"""
    if len(gold_df) == 0:
        print("   âš ï¸  No Gold data available for insights")
        return
    
    print("\nğŸ›ï¸ BUSINESS INTELLIGENCE INSIGHTS:")
    
    # Category breakdown
    top_categories = gold_df['technology_category'].value_counts().head(5)
    print("   ğŸ“‚ Top Categories:")
    for category, count in top_categories.items():
        print(f"      â€¢ {category}: {count} technologies")
    
    # FIXED: Use simplified Gold schema fields (no complex business fields)
    # Volume breakdown
    if 'mention_volume' in gold_df.columns:
        volume_counts = gold_df['mention_volume'].value_counts()
        print("   ğŸ“Š Mention Volumes:")
        for volume, count in volume_counts.items():
            print(f"      â€¢ {volume}: {count} technologies")
    
    # Data completeness
    if 'data_completeness' in gold_df.columns:
        avg_completeness = gold_df['data_completeness'].apply(
            lambda x: 'high' if x == 'complete' else x
        ).value_counts()
        print("   ğŸ“‹ Data Quality:")
        for quality, count in avg_completeness.items():
            print(f"      â€¢ {quality}: {count} technologies")
    
    # Top technologies by mentions
    top_techs = gold_df.nlargest(5, 'daily_mentions')
    print("   ğŸ”¥ Top Technologies by Mentions:")
    for _, row in top_techs.iterrows():
        category_emoji = {
            'ai_model': 'ğŸ¤–', 'ai_framework': 'ğŸ§ ', 'language': 'ğŸ’»',
            'framework': 'ğŸŒ', 'database': 'ğŸ—„ï¸', 'cloud': 'â˜ï¸'
        }.get(row['technology_category'], 'ğŸ”§')
        print(f"      {category_emoji} {row['technology']}: {row['daily_mentions']} mentions ({row['technology_category']})")
    
    # AI focus (hot category)
    ai_techs = gold_df[gold_df['technology_category'].str.startswith('ai')].nlargest(3, 'daily_mentions')
    if len(ai_techs) > 0:
        print("   ğŸ¤– AI/ML Technologies:")
        for _, row in ai_techs.iterrows():
            print(f"      â€¢ {row['technology']}: {row['daily_mentions']} mentions â†’ {row['mention_volume']} volume")


def generate_smart_next_steps(processing_info: Dict) -> None:
    """ğŸ§  Generate intelligent next steps based on what was processed"""
    strategy = processing_info.get('strategy', 'unknown')
    
    if strategy == 'auto_silver':
        remaining_silver = len(processing_info.get('missing_silver_dates', [])) - 1
        remaining_gold = len(processing_info.get('missing_gold_dates', []))
        
        print("\nğŸ”„ NEXT STEPS AFTER SILVER PROCESSING:")
        if remaining_silver > 0:
            print(f"   ğŸ“… Run again to process {remaining_silver} more Silver dates")
        if remaining_gold > 0:
            print(f"   ğŸ¥‡ Then process {remaining_gold} Gold dates")
        if remaining_silver == 0 and remaining_gold == 0:
            print("   ğŸ‰ All Silver processing complete! Gold will process next run.")
            
    elif strategy == 'auto_gold':
        remaining_gold = len(processing_info.get('missing_gold_dates', [])) - 1
        
        print("\nğŸ”„ NEXT STEPS AFTER GOLD PROCESSING:")
        if remaining_gold > 0:
            print(f"   ğŸ“… Run again to process {remaining_gold} more Gold dates")
        else:
            print("   ğŸ‰ All Gold processing complete! Medallion architecture current.")
            
    elif strategy == 'up_to_date':
        print("\nâœ… SYSTEM STATUS: UP TO DATE")
        print("   ğŸ¯ All medallion layers are current")
        print("   ğŸ“Š Ready for analytics and reporting")
        print("   ğŸ”„ Run Bronze pipeline to generate new data")
        
    elif strategy == 'manual':
        print("\nğŸ“… MANUAL PROCESSING COMPLETE")
        print("   ğŸ”„ Run without config for automatic processing")
        print("   ğŸ“Š Or specify another date for manual processing")
        
    else:
        print("\nğŸ’¡ GENERAL SUGGESTIONS:")
        print("   ğŸ”„ Re-run DAG for automatic processing")
        print("   ğŸ“Š Check data quality and completeness")


def generate_processing_overview(processing_info: Dict) -> None:
    """Generate overview of what processing occurred"""
    strategy = processing_info.get('strategy', 'unknown')
    
    strategy_explanations = {
        'auto_silver': 'ğŸ¥ˆ Automatically detected Bronzeâ†’Silver gaps and processed most recent',
        'auto_gold': 'ğŸ¥‡ Automatically detected Silverâ†’Gold gaps and processed most recent', 
        'up_to_date': 'âœ… All layers current - no processing needed',
        'manual': 'ğŸ“… Manual date processing',
        'no_data': 'âŒ No Bronze data available'
    }
    
    explanation = strategy_explanations.get(strategy, f'ğŸ”§ Strategy: {strategy}')
    print("\nğŸ§  SMART PROCESSING OVERVIEW:")
    print(f"   {explanation}")
    
    if 'bronze_dates' in processing_info:
        bronze_count = len(processing_info['bronze_dates'])
        silver_count = len(processing_info.get('silver_dates', []))
        gold_count = len(processing_info.get('gold_dates', []))
        
        print(f"   ğŸ“Š Data Landscape: {bronze_count} Bronze â†’ {silver_count} Silver â†’ {gold_count} Gold")


def generate_final_summary(**context) -> Dict:
    """ğŸ§  SMART Final Summary: Automatically detects what was processed and what's next"""
    try:
        status = assess_processing_status(**context)
        date_str = status['date']
        processing_info = status.get('processing_info', {})
        
        print("\nğŸ“Š SMART PROCESSING SUMMARY")
        print("=" * 55)
        print("ğŸ§  Mode: INTELLIGENT AUTO-DISCOVERY")
        print(f"ğŸ¯ Date: {date_str or 'None (no processing needed)'}")
        print(f"â° Completed: {datetime.now(timezone.utc).strftime('%Y-%m-%d %H:%M:%S')} UTC")
        print("âœ… Enhanced medallion architecture with business intelligence")
        
        # Show what the smart system detected and did
        generate_processing_overview(processing_info)
        
        # Handle case where no processing was needed
        if date_str is None:
            strategy = processing_info.get('strategy', 'unknown')
            if strategy == 'up_to_date':
                print("\nğŸ‰ RESULT: ALL MEDALLION LAYERS CURRENT")
                print("ğŸ“‹ Bronze, Silver, and Gold are all up to date")
                print("\nğŸ’¡ SYSTEM STATUS:")
                print("   âœ… Medallion architecture complete")
                print("   ğŸ“Š Ready for analytics and dashboards")
                print("   ğŸ”„ Run Bronze pipeline to process new data")
                print("   ğŸ“ˆ Consider setting up automated scheduling")
            else:
                print("\nâ© RESULT: NO PROCESSING NEEDED")
                print(f"ğŸ“‹ {processing_info.get('reason', 'Unknown reason')}")
                
            return {
                'status': 'success',
                'date': None,
                'pipeline_status': 'âœ… UP TO DATE' if strategy == 'up_to_date' else 'â© NO ACTION NEEDED',
                'message': processing_info.get('reason', 'No processing required'),
                'processing_info': processing_info,
                'completed_at': datetime.now(timezone.utc).isoformat()
            }
        
        # Medallion status overview
        print("\nğŸ—ï¸ MEDALLION ARCHITECTURE STATUS:")
        layers_status = [
            ("ğŸ¥‰ Bronze", status['bronze_count'], status['bronze_valid']),
            ("ğŸ¥ˆ Silver", status['silver_count'], status['silver_complete']), 
            ("ğŸ¥‡ Gold", status['gold_count'], status['gold_complete'])
        ]
        
        for layer_name, count, complete in layers_status:
            status_icon = "âœ…" if complete else "âŒ"
            print(f"   {layer_name}: {count:,} records {status_icon}")
        
        # Enhanced business insights for Gold
        if status['gold_complete'] and status['gold_count'] > 0:
            try:
                # FIXED: Use consistent Gold table name
                gold_path = get_enterprise_table_path(GOLD_TABLE_NAME, "gold")
                storage_options = get_minio_storage_options()
                gold_dt = DeltaTable(gold_path, storage_options=storage_options)
                gold_df = gold_dt.to_pandas(filters=[('date', '=', date_str)])
                
                generate_business_intelligence_insights(gold_df, date_str)
                        
            except Exception as e:
                print(f"   âš ï¸  Could not load detailed Gold insights: {e}")
        
        # Overall pipeline status
        if status['bronze_valid'] and status['silver_complete'] and status['gold_complete']:
            pipeline_status = "âœ… COMPLETE"
            message = "Full medallion processing successful"
        elif status['bronze_valid'] and status['silver_complete']:
            pipeline_status = "ğŸ”„ SILVER COMPLETE"
            message = "Silver complete, Gold in progress"
        elif status['bronze_valid']:
            pipeline_status = "ğŸ”„ BRONZE READY"
            message = "Bronze ready, processing needed"
        else:
            pipeline_status = "âŒ BLOCKED"
            message = "Bronze data issues blocking pipeline"
        
        print(f"\nğŸ¯ PIPELINE STATUS: {pipeline_status}")
        print(f"ğŸ“‹ Message: {message}")
        print("ğŸ›ï¸ Architecture: Bronze (raw) â†’ Silver (clean) â†’ Gold (business intelligence)")
        
        # Intelligent next steps
        generate_smart_next_steps(processing_info)
        
        print("\nğŸš€ Ready for: Analytics layer with statistical analysis + streaming integration")
        
        return {
            'status': 'success',
            'date': date_str,
            'pipeline_status': pipeline_status,
            'bronze_valid': status['bronze_valid'],
            'bronze_count': status['bronze_count'],
            'silver_complete': status['silver_complete'],
            'silver_count': status['silver_count'],
            'gold_complete': status['gold_complete'],
            'gold_count': status['gold_count'],
            'processing_info': processing_info,
            'message': message,
            'completed_at': datetime.now(timezone.utc).isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Summary generation failed: {e}")
        processing_info = get_processing_dates(**context)
        return {
            'status': 'failed',
            'error': str(e),
            'date': processing_info.get('target_date'),
            'processing_info': processing_info,
            'message': f'Summary error: {str(e)}'
        }